{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Combined Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Does not fit.                                                                        2\n",
       "Great phone!.                                                                        2\n",
       "Excellent product for the price.                                                     2\n",
       "Works great!.                                                                        2\n",
       "I would not recommend this place.                                                    2\n",
       "                                                                                    ..\n",
       "Talk about USELESS customer service.                                                 1\n",
       "Good value, great food, great service.                                               1\n",
       "Absolutely great.                                                                    1\n",
       "Cheap but hey it works.. Was pleasantly suprised given the low cost of this item.    1\n",
       "A PIECE OF JUNK THAT BROKE AFTER BEING ON MY PHONE FOR 2 DAYS!!!                     1\n",
       "Name: Review, Length: 1986, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(df['Review'])\n",
    "text_mat = t.texts_to_sequences(df['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vocab_size(matrix = text_mat):\n",
    "    \n",
    "    sequence_count = [set(text_mat[i])for i in range(len(text_mat))]\n",
    "    total = []\n",
    "    for i in range(len(sequence_count)):\n",
    "        for j in sequence_count[i]:\n",
    "            total.append(j)\n",
    "    \n",
    "    print(len(set(total))) #total number of unique words, or vocabulary of the text\n",
    "    \n",
    "    vocab = len(set(total))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_mat = []\n",
    "for i in range(len(text_mat)):\n",
    "    len_mat.append(len(text_mat[i]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of sequence : 32\n",
      "Average length of sequence : 10.598\n",
      "Median length of sequence : 9.0\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "print(\"Maximum length of sequence : {}\".format(max(len_mat)))\n",
    "print(\"Average length of sequence : {}\".format(mean(len_mat)))\n",
    "print(\"Median length of sequence : {}\".format(median(len_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_padding = sequence.pad_sequences(text_mat, maxlen=32, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_padding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    \n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, LSTM, Embedding\n",
    "    \n",
    "    model = Sequential()\n",
    "#     model.add(Dense(32,input_shape=(text_padding[0].shape)))\n",
    "#     model.add(Embedding(input_dim = find_vocab_size(text_mat)+1, output_dim=32, input_length = text_padding[0].shape, embeddings_regularizer= keras.regularizers.l2(0.001)))\n",
    "    model.add(Embedding(find_vocab_size()+1,128))\n",
    "    model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258\n"
     ]
    }
   ],
   "source": [
    "base_lstm_model = lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = text_padding, np.array(df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "ckpt = ModelCheckpoint('weights.hdf5', save_best_only=True, save_weights_only=True, monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/20\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0736 - accuracy: 0.9806 - val_loss: 0.6445 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0423 - accuracy: 0.9900 - val_loss: 1.0090 - val_accuracy: 0.7850\n",
      "Epoch 3/20\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0599 - accuracy: 0.9875 - val_loss: 1.2349 - val_accuracy: 0.7650\n",
      "Epoch 4/20\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.0534 - accuracy: 0.9894 - val_loss: 0.8869 - val_accuracy: 0.7900\n",
      "Epoch 5/20\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0382 - accuracy: 0.9925 - val_loss: 1.0680 - val_accuracy: 0.7750\n",
      "Epoch 6/20\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.0815 - accuracy: 0.9806 - val_loss: 0.9143 - val_accuracy: 0.7725\n"
     ]
    }
   ],
   "source": [
    "ep, bs = 20, 16\n",
    "base_lstm_model.fit(features,target, validation_split=0.2, epochs=ep, batch_size=bs, callbacks=[es, ckpt])\n",
    "NAME  = 'base_lstm_model_{}_ep_{}_bs'.format(ep,bs)\n",
    "base_lstm_model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
