{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/viole/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from Attention import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Activation\n",
    "\n",
    "from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Combined Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Works great.                                                                                                                                           2\n",
       "I love this place.                                                                                                                                     2\n",
       "Great Phone.                                                                                                                                           2\n",
       "Don't buy this product.                                                                                                                                2\n",
       "Great phone.                                                                                                                                           2\n",
       "                                                                                                                                                      ..\n",
       "I ordered this for sony Ericsson W810i but I think it only worked once (thats when I first used it).                                                   1\n",
       "Food was below average.                                                                                                                                1\n",
       "If you are reading this please don't go there.                                                                                                         1\n",
       "They had a toro tartare with a cavier that was extraordinary and I liked the thinly sliced wagyu with white truffle.                                   1\n",
       "Hot dishes are not hot, cold dishes are close to room temp.I watched staff prepare food with BARE HANDS, no gloves.Everything is deep fried in oil.    1\n",
       "Name: Review, Length: 1986, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1986, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(df['Review'])\n",
    "text_mat = t.texts_to_sequences(df['Review'])\n",
    "\n",
    "def get_tokenizer(tokenizer=t):\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vocab_size(matrix = text_mat):\n",
    "    \n",
    "    sequence_count = [set(text_mat[i])for i in range(len(text_mat))]\n",
    "    total = []\n",
    "    for i in range(len(sequence_count)):\n",
    "        for j in sequence_count[i]:\n",
    "            total.append(j)\n",
    "    \n",
    "    print(len(set(total))) #total number of unique words, or vocabulary of the text\n",
    "    \n",
    "    vocab = len(set(total))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_mat = []\n",
    "for i in range(len(text_mat)):\n",
    "    len_mat.append(len(text_mat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of sequence : 32\n",
      "Average length of sequence : 10.641490433031219\n",
      "Median length of sequence : 9.0\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "print(\"Maximum length of sequence : {}\".format(max(len_mat)))\n",
    "print(\"Average length of sequence : {}\".format(mean(len_mat)))\n",
    "print(\"Median length of sequence : {}\".format(median(len_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_padding = sequence.pad_sequences(text_mat, maxlen=32, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_padding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_model():\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(find_vocab_size()+1, 128))\n",
    "#     model.add(LSTM(128, return_sequences=True, recurrent_dropout=0.3, dropout=0.25))\n",
    "#     model.add(Attention())\n",
    "#     model.add(Dense(1))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "    \n",
    "#     model.summary()\n",
    "\n",
    "    from keras.layers import Input\n",
    "    \n",
    "    inputs = Input((text_padding[0].shape))\n",
    "    x = Embedding(find_vocab_size()+1, 128)(inputs)\n",
    "    att_in = LSTM(128, return_sequences=True, recurrent_dropout=0.3, dropout=0.3)(x)\n",
    "    att_out = Attention()(att_in)\n",
    "    outputs = Dense(1, activation='sigmoid', trainable =True)(att_out)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer='adam', metrics=['accuracy'], loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 32, 128)           417152    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32, 128)           131584    \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 128)               160       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 549,025\n",
      "Trainable params: 549,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/viole/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "attn_model = attention_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = text_padding, df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "ckpt = ModelCheckpoint('attn_weights.hdf5', save_best_only=True, save_weights_only=True, monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/viole/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1588 samples, validate on 398 samples\n",
      "Epoch 1/20\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.6151 - accuracy: 0.6285 - val_loss: 0.5770 - val_accuracy: 0.6960\n",
      "Epoch 2/20\n",
      "1588/1588 [==============================] - 4s 3ms/step - loss: 0.3659 - accuracy: 0.8552 - val_loss: 0.5748 - val_accuracy: 0.7186\n",
      "Epoch 3/20\n",
      "1588/1588 [==============================] - 4s 3ms/step - loss: 0.1949 - accuracy: 0.9339 - val_loss: 0.4950 - val_accuracy: 0.7889\n",
      "Epoch 4/20\n",
      "1588/1588 [==============================] - 4s 3ms/step - loss: 0.1141 - accuracy: 0.9685 - val_loss: 0.7083 - val_accuracy: 0.7538\n",
      "Epoch 5/20\n",
      "1588/1588 [==============================] - 4s 3ms/step - loss: 0.0970 - accuracy: 0.9754 - val_loss: 0.7835 - val_accuracy: 0.7462\n",
      "Epoch 6/20\n",
      "1588/1588 [==============================] - 4s 3ms/step - loss: 0.0958 - accuracy: 0.9704 - val_loss: 0.6704 - val_accuracy: 0.7538\n",
      "Epoch 7/20\n",
      "1588/1588 [==============================] - 4s 2ms/step - loss: 0.0568 - accuracy: 0.9849 - val_loss: 0.9223 - val_accuracy: 0.7286\n",
      "Epoch 8/20\n",
      "1588/1588 [==============================] - 4s 3ms/step - loss: 0.0526 - accuracy: 0.9861 - val_loss: 0.6013 - val_accuracy: 0.8015\n"
     ]
    }
   ],
   "source": [
    "ep, bs = 20, 16\n",
    "attn_model.fit(features,target, validation_split=0.2, epochs=ep, batch_size=bs, callbacks=[es, ckpt])\n",
    "NAME  = 'attn_lstm_model_{}_ep_{}_bs'.format(ep,bs)\n",
    "attn_model.save(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sent = [\"Negative\", \"Positive\"]\n",
    "\n",
    "def predict_on_test_sentences(model,sent):\n",
    "    \n",
    "    t = get_tokenizer()\n",
    "    test_converted = t.texts_to_sequences([sent])\n",
    "        \n",
    "    padded_text = sequence.pad_sequences(test_converted, padding='post', maxlen=32)\n",
    "    \n",
    "    assert padded_text.shape[1] == 32  \n",
    "    \n",
    "    y_prob = model.predict(padded_text)\n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    \n",
    "    print(\"Probability : {}\".format(y_prob[0][0]))\n",
    "    \n",
    "    return predicted_sent[int(round(y_prob[0][0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_to_predict = process_test_sentences(\"Excellent food.\")\n",
    "# y_prob = attn_model.predict(sent_to_predict) \n",
    "# y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model('base_lstm_model_20_ep_16_bs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.9664285778999329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_on_test_sentences(lstm_model, \"I absolutely love the food here. The service is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.0058388919569551945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_on_test_sentences(attn_model,\"I hate the food, bad service. Not even bothered to clean up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.9982967972755432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_on_test_sentences(attn_model, \"I absolutely love the food here. The service is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.0023912680335342884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_on_test_sentences(lstm_model,\"I hate the food, bad service. Not even bothered to clean up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
